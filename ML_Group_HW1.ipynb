{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6302a26",
   "metadata": {
    "id": "f6302a26"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-and-Load-Data\" data-toc-modified-id=\"Import-and-Load-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import and Load Data</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Trying-Out-Models\" data-toc-modified-id=\"Trying-Out-Models-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Trying Out Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Support-Vector-Machine\" data-toc-modified-id=\"Support-Vector-Machine-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Support Vector Machine</a></span></li><li><span><a href=\"#Decision-Trees-(Random-Forest,-Gradient-Boosting,-XGBoost)\" data-toc-modified-id=\"Decision-Trees-(Random-Forest,-Gradient-Boosting,-XGBoost)-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Decision Trees (Random Forest, Gradient Boosting, XGBoost)</a></span></li><li><span><a href=\"#Other-Models-(e.g.-Bagging-Classifier)\" data-toc-modified-id=\"Other-Models-(e.g.-Bagging-Classifier)-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Other Models (e.g. Bagging Classifier)</a></span></li></ul></li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model Evaluation</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a31f2b",
   "metadata": {
    "id": "b9a31f2b"
   },
   "source": [
    "## Import and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "KQexQhRsg9Hf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQexQhRsg9Hf",
    "outputId": "e36b2817-8b9a-4eb4-968f-b51ac1175652"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "rX_VtO9EhPxB",
   "metadata": {
    "id": "rX_VtO9EhPxB"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9725cdaa",
   "metadata": {
    "id": "9725cdaa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da6fb46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "9da6fb46",
    "outputId": "cc1c3b92-3814-4cec-d757-2a15eb9d99d1"
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_csv(\"loans.csv\",index_col=0 )\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a8777-46a0-4fdc-81fe-7dfbde8ef7aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d08a8777-46a0-4fdc-81fe-7dfbde8ef7aa",
    "outputId": "6e8decb6-8a91-480e-bd97-097dd3cb7a87"
   },
   "outputs": [],
   "source": [
    "# Exmaine all columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6eE9u6pOM1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9a6eE9u6pOM1",
    "outputId": "3f0fdaef-78a4-4140-c1f8-5a39d4a98869"
   },
   "outputs": [],
   "source": [
    "df = df[df.loan_status != 'Current'] # Drops loans with loan status 'Current'\n",
    "df.loan_status.value_counts()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waS7QR0ku8DJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "waS7QR0ku8DJ",
    "outputId": "3b4bb2a7-0b0f-4853-97fa-a89bc7bd056f"
   },
   "outputs": [],
   "source": [
    "#Set 'Fully Paid' and 'Does not meet the credit policy. Status:Fully Paid' to 1 and the rest to 0\n",
    "df['loan_status'] = df['loan_status'].replace({'Fully Paid': 1,'Charged Off': 0, 'Late (31-120 days)': 0,'Late (16-30 days)':0,'Default':0,'Does not meet the credit policy. Status:Charged Off':0,'Does not meet the credit policy. Status:Fully Paid':1})\n",
    "\n",
    "# Drop 'Issued' and ' In Grace Period' due to lack of information about whether loans are 'good' or 'bad'\n",
    "df = df[~df['loan_status'].isin(['Issued', 'In Grace Period'])]\n",
    "df.loan_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MyoI67oD3IdS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "MyoI67oD3IdS",
    "outputId": "b51da515-d48a-4f3f-912b-0e66c60e0ea5"
   },
   "outputs": [],
   "source": [
    "# Reformat 'term' column to int\n",
    "df['term'] = df['term'].str.extract('(\\d+)').astype(int)\n",
    "# Examine term variable post refromatting\n",
    "df.term.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ikPVZ_4n_bR3",
   "metadata": {
    "id": "ikPVZ_4n_bR3"
   },
   "outputs": [],
   "source": [
    "# Convert issue_d to datetime for ML\n",
    "df['issue_d'] = pd.to_datetime(df['issue_d'], format='%b-%Y')\n",
    "\n",
    "# Separate into year and month features\n",
    "df['issue_year'] = df['issue_d'].dt.year\n",
    "df['issue_month'] = df['issue_d'].dt.month\n",
    "\n",
    "df.drop(columns=['issue_d'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0H1rN091BFJm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "0H1rN091BFJm",
    "outputId": "4aea7cda-1b68-4fb1-c4ea-b6100bb1f3a9"
   },
   "outputs": [],
   "source": [
    "df.issue_month.head()\n",
    "\n",
    "# Cyclical encoding instead of one hot encoding month, to inform the model that January (1) may be close to December (12)\n",
    "df['issue_month_sin'] = np.sin(2 * np.pi * df['issue_month'] / 12)\n",
    "df['issue_month_cos'] = np.cos(2 * np.pi * df['issue_month'] / 12)\n",
    "\n",
    "df.drop(columns=['issue_month'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "woGHPsY9C9_w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 967
    },
    "id": "woGHPsY9C9_w",
    "outputId": "368304e5-2683-428e-d040-73338da5a18f"
   },
   "outputs": [],
   "source": [
    "# Examine emp_title and emp_length variables\n",
    "df.emp_title.dropna().value_counts()\n",
    "df.emp_length.dropna().value_counts()\n",
    "df.emp_title.isna().sum()\n",
    "df.emp_length.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "we5hgbMkJUbI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "we5hgbMkJUbI",
    "outputId": "1fbea615-c8e3-4ab6-cc52-e58b4494862b"
   },
   "outputs": [],
   "source": [
    "df.application_type.value_counts()\n",
    "# We can safely drop this\n",
    "df = df.drop('application_type',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J9a0baHNMbOi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "J9a0baHNMbOi",
    "outputId": "e3defcbe-d274-4627-bdbd-510613af7f85"
   },
   "outputs": [],
   "source": [
    "# Examining more features\n",
    "df.title.value_counts()\n",
    "df.earliest_cr_line.value_counts()\n",
    "df.last_pymnt_d.value_counts()\n",
    "df.last_credit_pull_d.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dPD2yaIf7Be1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "dPD2yaIf7Be1",
    "outputId": "3697af27-8fea-4de7-f3f6-d575fff2d31f"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zf4kFpmU3Zx5",
   "metadata": {
    "id": "zf4kFpmU3Zx5"
   },
   "outputs": [],
   "source": [
    "# Dropping more columns that likely will not be strong predictors\n",
    "df = df.drop(['emp_title','zip_code','title','emp_length','url','id','member_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bj4jdZQvokuv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bj4jdZQvokuv",
    "outputId": "e4e1844a-4177-487d-d675-d65fcff4484b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df1 = df.copy()\n",
    "\n",
    "# Drop all columns with any missing values\n",
    "df1 = df1.dropna(axis=1, how='any')\n",
    "\n",
    "# Check remaining shape\n",
    "print(\"df1 shape after dropping all columns with missing values:\", df1.shape)\n",
    "\n",
    "\n",
    "df2 = df.copy()\n",
    "\n",
    "# Drop columns with more than 50% missing values\n",
    "threshold = 0.5\n",
    "df2 = df2.dropna(axis=1, thresh=int((1-threshold) * len(df2)))\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_columns = df2.select_dtypes(include=['number']).columns\n",
    "categorical_columns = df2.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute missing values for numerical columns with mean\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "df2[numerical_columns] = num_imputer.fit_transform(df2[numerical_columns]).copy()\n",
    "\n",
    "# Impute missing values for categorical columns with most frequent value\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df2[categorical_columns] = cat_imputer.fit_transform(df2[categorical_columns]).copy()\n",
    "\n",
    "# Check final shape\n",
    "print(\"df2 shape after partial drop + imputation:\", df2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0oWyUN2NXao9",
   "metadata": {
    "id": "0oWyUN2NXao9"
   },
   "outputs": [],
   "source": [
    "df2['earliest_cr_line'] = pd.to_datetime(df2['earliest_cr_line'], format='%b-%Y')\n",
    "\n",
    "df2['earliest_cr_line_year'] = df2['earliest_cr_line'].dt.year\n",
    "df2['earliest_cr_line_month'] = df2['earliest_cr_line'].dt.month\n",
    "\n",
    "df2.drop(columns=['earliest_cr_line'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZQZvqEONXy87",
   "metadata": {
    "id": "ZQZvqEONXy87"
   },
   "outputs": [],
   "source": [
    "def parse_dates(date):\n",
    "    try:\n",
    "        return pd.to_datetime(date, format='%b-%Y')  # Try parsing as 'Oct-2015'\n",
    "    except:\n",
    "        try:\n",
    "            return pd.to_datetime(date, format='%Y')  # Try parsing as '2015'\n",
    "        except:\n",
    "            return pd.NaT  # Assign NaT if parsing fails\n",
    "\n",
    "df2['last_pymnt_d'] = df2['last_pymnt_d'].astype(str).apply(parse_dates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ckIEyolBaKkI",
   "metadata": {
    "id": "ckIEyolBaKkI"
   },
   "outputs": [],
   "source": [
    "df2['last_pymnt_d_year'] = df2['last_pymnt_d'].dt.year\n",
    "df2['last_pymnt_d_month'] = df2['last_pymnt_d'].dt.month\n",
    "\n",
    "df2.drop(columns=['last_pymnt_d'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dDZT2obMX-DD",
   "metadata": {
    "id": "dDZT2obMX-DD"
   },
   "outputs": [],
   "source": [
    "df2['last_credit_pull_d'] = pd.to_datetime(df2['last_credit_pull_d'], format='%b-%Y')\n",
    "\n",
    "df2['last_credit_pull_d_year'] = df2['last_credit_pull_d'].dt.year\n",
    "df2['last_credit_pull_d_month'] = df2['last_credit_pull_d'].dt.month\n",
    "\n",
    "df2.drop(columns=['last_credit_pull_d'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l4wY7QQ_YAVm",
   "metadata": {
    "id": "l4wY7QQ_YAVm"
   },
   "outputs": [],
   "source": [
    "df2['earliest_cr_line_month_sin'] = np.sin(2 * np.pi * df2['earliest_cr_line_month'] / 12)\n",
    "df2['earliest_cr_line_month_cos'] = np.cos(2 * np.pi * df2['earliest_cr_line_month'] / 12)\n",
    "\n",
    "df2.drop(columns=['earliest_cr_line_month'], inplace=True)\n",
    "\n",
    "df2['last_pymnt_d_sin'] = np.sin(2 * np.pi * df2['last_pymnt_d_month'] / 12)\n",
    "df2['last_pymnt_d_cos'] = np.cos(2 * np.pi * df2['last_pymnt_d_month'] / 12)\n",
    "\n",
    "df2.drop(columns=['last_pymnt_d_month'], inplace=True)\n",
    "\n",
    "df2['last_credit_pull_d_sin'] = np.sin(2 * np.pi * df2['last_credit_pull_d_month'] / 12)\n",
    "df2['last_credit_pull_d_cos'] = np.cos(2 * np.pi * df2['last_credit_pull_d_month'] / 12)\n",
    "\n",
    "df2.drop(columns=['last_credit_pull_d_month'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vf_kSdE4HynC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vf_kSdE4HynC",
    "outputId": "aa33b643-f471-41e3-800a-7d2314f2a45e"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df1_categorical = ['term','grade','sub_grade','home_ownership', 'verification_status','pymnt_plan','purpose', 'addr_state','initial_list_status']\n",
    "\n",
    "df2_categorical = df1_categorical \n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "encoded_cats_df2 = encoder.fit_transform(df2[df2_categorical])\n",
    "\n",
    "# Convert to DataFrame\n",
    "encoded_df2 = pd.DataFrame(encoded_cats_df2, columns=encoder.get_feature_names_out(df2_categorical))\n",
    "\n",
    "# Drop original categorical columns and concatenate encoded ones\n",
    "df2 = df2.drop(columns=df2_categorical).reset_index(drop=True)\n",
    "df2 = pd.concat([df2, encoded_df2], axis=1)\n",
    "\n",
    "print(\"df2 shape after one-hot encoding:\", df2.shape)\n",
    "\n",
    "encoded_cats_df1 = encoder.fit_transform(df1[df1_categorical])\n",
    "\n",
    "# Convert to DataFrame\n",
    "encoded_df1 = pd.DataFrame(encoded_cats_df1, columns=encoder.get_feature_names_out(df1_categorical))\n",
    "\n",
    "# Drop original categorical columns and concatenate encoded ones\n",
    "df1 = df1.drop(columns=df1_categorical).reset_index(drop=True)\n",
    "df1 = pd.concat([df1, encoded_df1], axis=1)\n",
    "print(\"df1 shape after one-hot encoding:\", df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w1fj49PgEHD8",
   "metadata": {
    "id": "w1fj49PgEHD8"
   },
   "outputs": [],
   "source": [
    "numerical_columns = ['loan_amnt',\n",
    " 'funded_amnt',\n",
    " 'funded_amnt_inv',\n",
    " 'term',\n",
    " 'int_rate',\n",
    " 'installment',\n",
    " 'annual_inc',\n",
    " 'dti',\n",
    " 'delinq_2yrs',\n",
    " 'inq_last_6mths',\n",
    " 'mths_since_last_delinq',\n",
    " 'mths_since_last_record',\n",
    " 'open_acc',\n",
    " 'pub_rec',\n",
    " 'revol_bal',\n",
    " 'revol_util',\n",
    " 'total_acc',\n",
    " 'out_prncp',\n",
    " 'out_prncp_inv',\n",
    " 'total_pymnt',\n",
    " 'total_pymnt_inv',\n",
    " 'total_rec_prncp',\n",
    " 'total_rec_int',\n",
    " 'total_rec_late_fee',\n",
    " 'recoveries',\n",
    " 'collection_recovery_fee',\n",
    " 'last_pymnt_amnt',\n",
    " 'collections_12_mths_ex_med',\n",
    " 'mths_since_last_major_derog',\n",
    " 'policy_code',\n",
    " 'annual_inc_joint',\n",
    " 'dti_joint',\n",
    " 'acc_now_delinq',\n",
    " 'tot_coll_amt',\n",
    " 'tot_cur_bal',\n",
    " 'open_acc_6m',\n",
    " 'open_il_6m',\n",
    " 'open_il_12m',\n",
    " 'open_il_24m',\n",
    " 'mths_since_rcnt_il',\n",
    " 'total_bal_il',\n",
    " 'il_util',\n",
    " 'open_rv_12m',\n",
    " 'open_rv_24m',\n",
    " 'max_bal_bc',\n",
    " 'all_util',\n",
    " 'total_rev_hi_lim',\n",
    " 'inq_fi',\n",
    " 'total_cu_tl',\n",
    " 'inq_last_12m', 'issue_year', 'last_credit_pull_d_year', 'last_pymnt_d_year','earliest_cr_line_year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OAwF3vkRBDmk",
   "metadata": {
    "id": "OAwF3vkRBDmk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "common_numerical = df1.columns.intersection(numerical_columns)\n",
    "common_numerical2 = df2.columns.intersection(numerical_columns)\n",
    "df1[common_numerical] = scaler.fit_transform(df1[common_numerical])\n",
    "df2[common_numerical2] = scaler.fit_transform(df2[common_numerical2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yqEo2esCJNuV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "yqEo2esCJNuV",
    "outputId": "9f363771-80c1-4c46-ae3a-e5d30c162f37"
   },
   "outputs": [],
   "source": [
    "df1.loan_status.value_counts()\n",
    "df2.loan_status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KZ3A8nVryZaH",
   "metadata": {
    "id": "KZ3A8nVryZaH"
   },
   "source": [
    "From the value_counts() function, we gather that the datasets are imbalanced. To resolve this issue, we can use SMOTE (Synthetic Minority Oversampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4wrEKGGLMroL",
   "metadata": {
    "id": "4wrEKGGLMroL"
   },
   "outputs": [],
   "source": [
    "df1['loan_status'] = df1['loan_status'].astype(int)\n",
    "df2['loan_status'] = df2['loan_status'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gO1wSercJ1pi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gO1wSercJ1pi",
    "outputId": "2ee822f3-70af-4267-fcb0-3b4708c39e78"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define target variable\n",
    "target = 'loan_status'\n",
    "\n",
    "\n",
    "X1 = df1.drop(columns=[target])\n",
    "y1 = df1[target]\n",
    "\n",
    "X2 = df2.drop(columns=[target])\n",
    "y2 = df2[target]\n",
    "\n",
    "# Apply SMOTE separately to df1 and df2\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "X1_resampled, y1_resampled = smote.fit_resample(X1, y1)\n",
    "X2_resampled, y2_resampled = smote.fit_resample(X2, y2)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "df1_balanced = pd.DataFrame(X1_resampled, columns=X1.columns)\n",
    "df1_balanced[target] = y1_resampled\n",
    "\n",
    "df2_balanced = pd.DataFrame(X2_resampled, columns=X2.columns)\n",
    "df2_balanced[target] = y2_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y9wrWbLSNk0j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "y9wrWbLSNk0j",
    "outputId": "e6a779fe-d24a-4e31-ffba-b7b5b7129dba"
   },
   "outputs": [],
   "source": [
    "df1_balanced.loan_status.value_counts()\n",
    "df2_balanced.loan_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31Z20g9WN-7L",
   "metadata": {
    "id": "31Z20g9WN-7L"
   },
   "outputs": [],
   "source": [
    "X1 = df1_balanced.drop(columns=[target])\n",
    "y1 = df1_balanced[target]\n",
    "\n",
    "X2 = df2_balanced.drop(columns=[target])\n",
    "y2 = df2_balanced[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BKfANxsxNwX7",
   "metadata": {
    "id": "BKfANxsxNwX7"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X1,y1,test_size=0.3,random_state=42,stratify=y1)\n",
    "X_train2,X_test2,y_train2,y_test2 = train_test_split(X2,y2,test_size=0.3,random_state=42,stratify=y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C9RHr6etVmbL",
   "metadata": {
    "id": "C9RHr6etVmbL"
   },
   "outputs": [],
   "source": [
    "df2_sample = df2_balanced.sample(n=50000, random_state=42)\n",
    "\n",
    "X = df2_sample.drop(columns=['loan_status'])\n",
    "y = df2_sample['loan_status']\n",
    "\n",
    "corr_matrix = pd.DataFrame(X).corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "X = pd.DataFrame(X).drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MLWhrtbFVmXA",
   "metadata": {
    "id": "MLWhrtbFVmXA"
   },
   "outputs": [],
   "source": [
    "lasso = LogisticRegression(penalty='l1', solver='saga', max_iter=500)\n",
    "param_dist = {'C': np.logspace(-4, 4, 10)}  # Log-distributed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uUQzeclBVmLC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "uUQzeclBVmLC",
    "outputId": "7f304d0e-d803-4e12-a39e-e52c0b6ae0eb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(lasso, param_distributions=param_dist,\n",
    "                                   n_iter=5, scoring='roc_auc', cv=3, n_jobs=-1, random_state=42)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "best_lasso = random_search.best_estimator_\n",
    "lasso_coefficients = best_lasso.coef_.flatten()\n",
    "selected_features = X.columns[lasso_coefficients != 0]\n",
    "\n",
    "print(f\"Selected {len(selected_features)} features using Lasso:\")\n",
    "print(selected_features)\n",
    "print(f\"Best Regularization Parameter (C): {random_search.best_params_['C']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9B8tv7VClrPh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "9B8tv7VClrPh",
    "outputId": "77a4dff9-585f-4860-d873-4e488e771d17"
   },
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Coefficient': lasso_coefficients})\n",
    "\n",
    "# Select only non-zero coefficients\n",
    "feature_importance = feature_importance[feature_importance['Coefficient'] != 0]\n",
    "\n",
    "# Sort features by absolute coefficient value in descending order\n",
    "feature_importance = feature_importance.reindex(feature_importance['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "\n",
    "feature_importance.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11170589-60e9-43b1-827a-3c2fae0ddd81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "481e6bb3",
   "metadata": {
    "id": "481e6bb3"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    " - Handle missing values\n",
    " - Encode categorical variables, scale data (if you wish), feature selection, etc.\n",
    " - Split the dataset into features (X) and target variable (y)\n",
    " - Split into training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3820c653-d05d-46f3-9989-96ec781305cc",
   "metadata": {
    "id": "3820c653-d05d-46f3-9989-96ec781305cc"
   },
   "source": [
    "# feature selection\n",
    "1. Loan Amount (loan_amnt)\n",
    "2. Annual Income (annual_inc)\n",
    "3. Debt-to-Income Ratio (dti)\n",
    "4. Loan Term (term)\n",
    "6. Employment Length (emp_length)\n",
    "7. Grade and Subgrade (grade, sub_grade) credit grading FICO score\n",
    "9. Interest Rate (int_rate)\n",
    "\n",
    "\n",
    "5. Purpose of Loan (purpose) ?C\n",
    "5. Home Ownership Status (home_ownership)? C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "E1r3Ht-Yk-MV",
   "metadata": {
    "id": "E1r3Ht-Yk-MV"
   },
   "source": [
    "normalizer - shubhaan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mkWglUbIleCT",
   "metadata": {
    "id": "mkWglUbIleCT"
   },
   "source": [
    "feature selection - lasso, decisiontrees/randomforests - generate feature importance plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kVn_KZjZkgjN",
   "metadata": {
    "id": "kVn_KZjZkgjN"
   },
   "source": [
    "Creating X and Y and train_test_split and LASSO - shubhaan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290ddb0",
   "metadata": {
    "id": "5290ddb0"
   },
   "source": [
    "## Trying Out Models\n",
    "\n",
    "Here, you want to try each type of machine learning model and perform the train-test-loop: identify the best hyperparameters for the model to perform well in training and validation. GridSearchCV is likely relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f0117",
   "metadata": {
    "id": "c25f0117"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b9ac1",
   "metadata": {
    "id": "6c9b9ac1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47702d54",
   "metadata": {
    "id": "47702d54"
   },
   "source": [
    "### Decision Trees (Random Forest, Gradient Boosting, XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d2373",
   "metadata": {
    "id": "972d2373"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48d04428",
   "metadata": {
    "id": "48d04428"
   },
   "source": [
    "### Other Models (e.g. Bagging Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257f5fc",
   "metadata": {
    "id": "3257f5fc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ece7d77",
   "metadata": {
    "id": "3ece7d77"
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Compare the best models' performance on the test data. Which one does the best? Which one the worst? Why do you think this is the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ed303",
   "metadata": {
    "id": "a48ed303"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
